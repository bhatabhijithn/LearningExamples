{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from tflearn.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imdb train/test split for 10000 line items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.iro.umontreal.ca/~lisa/deep/data/imdb.pkl\n"
     ]
    }
   ],
   "source": [
    "train, test, _ = imdb.load_data(path = \"imdb.pkl\", n_words = 10000, valid_portion=0.1)\n",
    "trainX, trainY = train\n",
    "testX, testY = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of Train X & Y:\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "Train X[0] :\n",
      "[17, 25, 10, 406, 26, 14, 56, 61, 62, 323, 4]\n",
      "Train Y[0] :\n",
      "0\n",
      "Train X[0] :\n",
      "[[16, 586, 32, 885, 17, 39, 68, 31, 2994, 2389, 328, 4], [1, 2, 1, 139, 6, 130, 1, 5, 6, 25, 105, 4730, 40], [6691, 1, 10, 333, 10, 17, 27, 4, 34, 181, 6, 1418, 256, 4], [30, 287, 142, 2216, 707, 3763, 20, 68, 57, 30, 37, 309, 14, 4], [224, 3, 371, 3, 1, 4, 128, 37, 16, 90, 48, 1247, 8, 79, 294, 913, 1709, 4], [17, 10, 2, 6409, 25, 325, 7, 3161, 4, 2588, 1977, 176, 3, 26, 50, 35, 70, 1050, 395, 4], [16, 104, 32, 138, 152, 16, 49, 17, 25, 48, 89, 3, 26, 16, 128, 91, 1445, 7, 164, 14, 4], [70, 922, 87, 394, 25, 3, 129, 883, 53, 457, 86, 879, 87, 70, 297, 42, 41, 86, 1752, 14, 40], [2, 118, 35, 6186, 5, 2, 242, 10, 397, 4, 14, 20, 6, 456, 7, 2, 1938, 7, 1, 5, 1, 4]]\n",
      "Train Y[0] :\n",
      "[0, 0, 1, 0, 0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of Train X & Y:\")\n",
    "print(type(trainX))\n",
    "print(type(trainY))\n",
    "print(\"Train X[0] :\")\n",
    "print (trainX[0])\n",
    "print(\"Train Y[0] :\")\n",
    "print (trainY[0])\n",
    "print(\"Train X[0] :\")\n",
    "print (trainX[1:10])\n",
    "print(\"Train Y[0] :\")\n",
    "print (trainY[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16, 586 represents the number of occurance of the words in pickled index\n",
    "#### 0,0,1 represents the sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "### Sequence padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = pad_sequences(trainX, maxlen=100, value = 0.)\n",
    "testX = pad_sequences(testX, maxlen=100, value = 0.)\n",
    "\n",
    "#Convert to Binary vectors\n",
    "trainY = to_categorical(trainY, nb_classes=0.)\n",
    "testY = to_categorical(testY, nb_classes=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = tflearn.input_data([None, 100])\n",
    "net = tflearn.embedding(net, input_dim=10000, output_dim=128)\n",
    "net = tflearn.lstm(net, 128, dropout=0.8)\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='adam', learning_rate=0.001, loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7039  | time: 250.862s\n",
      "| Adam | epoch: 010 | loss: 0.00000 - acc: 0.9819 -- iter: 22496/22500\n",
      "Training Step: 7040  | time: 260.441s\n",
      "| Adam | epoch: 010 | loss: 0.00000 - acc: 0.9837 | val_loss: 0.67210 - val_acc: 0.8028 -- iter: 22500/22500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(trainX, trainY, validation_set =(testX, testY), show_metric = True, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
